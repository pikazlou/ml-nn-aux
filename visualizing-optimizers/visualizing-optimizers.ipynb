{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "531d278b",
   "metadata": {},
   "source": [
    "## Visualizing optimizers\n",
    "This notebook visualizes common optimizers used during neural networks training. The idea is based on these visualizations: https://imgur.com/a/Hqolp#NKsFHJb\n",
    "\n",
    "The goal was to reproduce similar animations and try different surfaces.\n",
    "\n",
    "Unfortunately matplotlib is not suitable for 3D plotting of several elements on the same plot (surface and lines for optimizers): it can't correctly infer overlapping since the surface is treated as 2D image once it is created.\n",
    "\n",
    "So I searched for alternatives and decided to use PyVista, which supports true 3D rendering.\n",
    "\n",
    "Generating GIFs from PyVista turned out to be problematic: lines and legend kept changing colors between frames so I had to use some workarounds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e9d0e6",
   "metadata": {},
   "source": [
    "## Preparation part: methods and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42842dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 13:26:12.086892: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pyvista as pv\n",
    "from pyvista import examples\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421a1367",
   "metadata": {},
   "source": [
    "The next cell is the workaround to produce consistent frames for GIF with PyVista: reduce the amount of colors. Since standard matplotlib's color maps have lots of color shades, I decided to have simpler color map - just 11 colors in it moving from red to blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8cc048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_cmap = colors.ListedColormap([(1.0-i/20, 0.5, 0.5+i/20) for i in range(0, 11)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f2e599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_grid(scale, func):\n",
    "    \"\"\"Creates XY grid and evaluates function on it to produce Z.\n",
    "\n",
    "    Parameters:\n",
    "    scale -- defines range for X and Y to be (-scale, scale)\n",
    "    func -- function to evaluate on XY, must take two parameters: x, y. Must produce tf.Tensor.\n",
    "    \"\"\"\n",
    "    x = np.arange(-scale, scale, scale / 20, dtype='float32')\n",
    "    y = np.arange(-scale, scale, scale / 20, dtype='float32')\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    z = func(x, y).numpy()\n",
    "    return x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1595a94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_surface(x, y, z):\n",
    "    \"\"\"Renders surface based on XYZ grid.\"\"\"\n",
    "    grid = pv.StructuredGrid(x, y, z)\n",
    "    grid['scalars'] = -z.ravel(order='f')\n",
    "    plotter = pv.Plotter() \n",
    "    plotter.add_mesh(grid, scalars='scalars', cmap=surface_cmap, show_edges=True, opacity=1.0)\n",
    "    plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b1f9cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lines_optimizer(opt, func, start_x, start_y, vertical_adjustment, number_of_steps=100):\n",
    "    \"\"\"Calculates optimizer line which represents the path of gradient descent for the specified function.\n",
    "\n",
    "    Parameters:\n",
    "    opt -- instance of optimizer from `keras.optimizers` package.\n",
    "    func -- function we want to minimize with the optimizer\n",
    "    start_x, start_y -- starting point for optimizer\n",
    "    vertical_adjustment -- technical attribute, defines the elevation of optimizer line to avoid intersecting optimizer lines with surface and between each other, should me some small value\n",
    "    number_of_steps -- number of steps for optimizer to make\n",
    "    \n",
    "    Returns:\n",
    "    list of 3-elements lists, which define line segments in 3D\n",
    "    \"\"\"\n",
    "    varx = tf.Variable(start_x)\n",
    "    vary = tf.Variable(start_y)\n",
    "    loss = lambda: func(varx, vary)\n",
    "    result = [[varx.numpy(), vary.numpy(), func(varx.numpy(), vary.numpy())+vertical_adjustment]]\n",
    "    stopped = False\n",
    "    for i in range(0, number_of_steps):\n",
    "        if not stopped:\n",
    "            step_count = opt.minimize(loss, [varx, vary]).numpy()\n",
    "        func_value = func(varx.numpy(), vary.numpy())\n",
    "        if abs(func_value) > 1000:\n",
    "            stopped = True\n",
    "        result.append([varx.numpy(), vary.numpy(), func_value+vertical_adjustment])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66ca8dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_animation(x, y, z, optimizer_lines, filename):\n",
    "    \"\"\"Creates GIF animation and saves it to the specified file.\n",
    "\n",
    "    Parameters:\n",
    "    x, y, z -- grid to render surface\n",
    "    optimizer_lines -- list of 3-element lists, which define line segments in 3D\n",
    "    filename -- file to save GIF to\n",
    "    \"\"\"\n",
    "    grid = pv.StructuredGrid(x, y, z)\n",
    "    grid['scalars'] = -z.ravel(order='f')\n",
    "\n",
    "    plotter = pv.Plotter(off_screen=True, lighting=None) \n",
    "    #plotter.open_movie(\"anim.mp4\")\n",
    "    plotter.open_gif(filename)\n",
    "    \n",
    "    plotter.add_legend(legend, bcolor=(0.1, 0.1, 0.1))\n",
    "\n",
    "    plotter.add_mesh(grid, scalars='scalars', cmap=surface_cmap, show_edges=True, opacity=1.0, show_scalar_bar=False)\n",
    "\n",
    "    actors = []\n",
    "    for i in range(2, gradient_steps):\n",
    "        for actor in actors:\n",
    "            plotter.remove_actor(actor)\n",
    "        actors = []\n",
    "        for opt_ind in range(0, len(optimizers)):\n",
    "            actors.append(plotter.add_mesh(pv.MultipleLines(optimizer_lines[opt_ind][:i]), scalars=[0]*i, cmap=cmaps[opt_ind], line_width=4, show_scalar_bar=False))\n",
    "        plotter.write_frame()\n",
    "\n",
    "    plotter.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474ba149",
   "metadata": {},
   "source": [
    "## List of optimizers to test\n",
    "Here is the list of optimizers we will test, feel free to modify the list.\n",
    "Note that during the simulation SGD and SGD+momentum were so slow that I decided to give them unfair advantage - increasing their learning rate, just to get more action out of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba136812",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of tuples (label, color, optimizer)\n",
    "#SGD and SGD+momentum were so slow during simulations that their learning rate was increased to have better visualization\n",
    "optimizers = [('SGD', (1.0, 0.1, 0.1), keras.optimizers.SGD(learning_rate=0.05)),\n",
    "              ('SGD+momentum', (1.0, 0.8, 0.1), keras.optimizers.SGD(learning_rate=0.05, momentum=0.5)),\n",
    "              ('RMSprop', (0.0, 1.0, 0.1), keras.optimizers.RMSprop(learning_rate=0.01)),\n",
    "              ('Adam', (0.0, 0.5, 1.0), keras.optimizers.Adam(learning_rate=0.01))\n",
    "             ]\n",
    "\n",
    "cmaps = [colors.ListedColormap([opt[1]]) for opt in optimizers]\n",
    "\n",
    "#precalculate legend for the plot\n",
    "legend = [[opt[0], opt[1]] for opt in optimizers]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc3c707",
   "metadata": {},
   "source": [
    "## Fun part: let's try optimizers in action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69edc8ac",
   "metadata": {},
   "source": [
    "### Simple slope\n",
    "The simplest example is just a sloped plane. It has decent slope in the direction of Y and a tiny slope in the direction of X. Classic gradient descent optimizers respond to this accordingly: they go alongside Y and almost ignore X direction. But note how RMSprop and Adam treat both slopes equally! Don't be confused by SGDs beating RMSprop and Adam by such a large margin - remember that SGDs has 5x times larger learning rate in our simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac3e5027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 13:26:53.887256: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def f(x, y):\n",
    "    return tf.identity(-y-0.001*x)\n",
    "\n",
    "x, y, z = evaluate_on_grid(0.5, f)\n",
    "#show_surface(x, y, z)\n",
    "\n",
    "start_x = np.float64(0.01)\n",
    "start_y = np.min(y) * 0.9\n",
    "\n",
    "filename = 'simple-slope.gif'\n",
    "\n",
    "gradient_steps = 100\n",
    "\n",
    "vertical_adjustment = (np.max(z) - np.min(z))/30\n",
    "optimizer_lines = [lines_optimizer(opt[2], f, start_x, start_y, (ind+1)*vertical_adjustment, number_of_steps=gradient_steps) for ind, opt in enumerate(optimizers)]\n",
    "\n",
    "create_animation(x, y, z, optimizer_lines, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea9283a",
   "metadata": {},
   "source": [
    "![animation](simple-slope.gif \"Simple slope\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1177987f",
   "metadata": {},
   "source": [
    "### Parabolic saddle\n",
    "Now the classic shape with a saddle point - parabolic shape: y^2 - x^2. The optimizers start at x close to 0, which makes the derivative over X axis close to 0 as well. Note how classic gradient descent optimizers struggle with this small derivative. RMSprop and Adam on the other hand have absolutely no problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "685000b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    return tf.square(y) - tf.square(x)\n",
    "\n",
    "filename = 'parabolic-saddle.gif'\n",
    "\n",
    "x, y, z = evaluate_on_grid(0.5, f)\n",
    "#show_surface(x, y, z)\n",
    "\n",
    "start_x = np.float64(0.00001)\n",
    "start_y = np.min(y) * 0.9\n",
    "\n",
    "gradient_steps = 100\n",
    "\n",
    "vertical_adjustment = (np.max(z) - np.min(z))/30\n",
    "optimizer_lines = [lines_optimizer(opt[2], f, start_x, start_y, (ind+1)*vertical_adjustment, number_of_steps=gradient_steps) for ind, opt in enumerate(optimizers)]\n",
    "\n",
    "create_animation(x, y, z, optimizer_lines, filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6a0a8d",
   "metadata": {},
   "source": [
    "![animation](parabolic-saddle.gif \"Parabolic saddle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37886f06",
   "metadata": {},
   "source": [
    "### Sloped cylinder\n",
    "Well, technically not a cylinder but a parabola, but it doesn't matter here. The parabola is extended along X axis with a small slope. RMSprop and Adam again respect even small slope, nothing new here. But note how quick Adam is!\n",
    "\n",
    "(Below is my attempt to explain these differences, but take it with some grain of salt, since I haven't invested much into analysis) \n",
    "\n",
    "RMSprop and SGD+momentum have similar speed, but most likely due to different reasons: RMSprop due to rescaling of gradient, SGD+momentum due to momentum. Adam has both of these and additionally has second-order momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fc4de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    return tf.square(y) - 0.1*x\n",
    "\n",
    "x, y, z = evaluate_on_grid(0.5, f)\n",
    "#show_surface(x, y, z)\n",
    "\n",
    "start_x = np.min(x) * 0.9\n",
    "start_y = np.min(y) * 0.9\n",
    "\n",
    "filename = 'sloped-cylinder.gif'\n",
    "\n",
    "gradient_steps = 100\n",
    "\n",
    "vertical_adjustment = (np.max(z) - np.min(z))/30\n",
    "optimizer_lines = [lines_optimizer(opt[2], f, start_x, start_y, (ind+1)*vertical_adjustment, number_of_steps=gradient_steps) for ind, opt in enumerate(optimizers)]\n",
    "\n",
    "create_animation(x, y, z, optimizer_lines, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255fe097",
   "metadata": {},
   "source": [
    "![animation](sloped-cylinder.gif \"Sloped cylinder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fde2c3",
   "metadata": {},
   "source": [
    "### Going around hill\n",
    "A bit more complex version of saddle point just to have some fun. See how presence of momentum brings success here: both SGD+momentum and Adam reached the bottom quickly (well, for SGD+momentum sort of, since it has 5x learning rate). RMSprop is the last one but remember it has 5x lower rate than SGDs.\n",
    "\n",
    "Also note how Adam does some exploration before converging to the minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97bcd727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    return tf.sin(3+ 1/(tf.square(x) + 0.45)) + tf.sin(3 + 1/(tf.square(y) + 0.45)) - 0.6*y\n",
    "\n",
    "x, y, z = evaluate_on_grid(0.5, f)\n",
    "#show_surface(x, y, z)\n",
    "\n",
    "start_x = np.float64(0.01)\n",
    "start_y = np.min(y) * 0.9\n",
    "\n",
    "filename = 'around-hill.gif'\n",
    "\n",
    "gradient_steps = 100\n",
    "\n",
    "vertical_adjustment = (np.max(z) - np.min(z))/30\n",
    "optimizer_lines = [lines_optimizer(opt[2], f, start_x, start_y, (ind+1)*vertical_adjustment, number_of_steps=gradient_steps) for ind, opt in enumerate(optimizers)]\n",
    "\n",
    "create_animation(x, y, z, optimizer_lines, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008fa70a",
   "metadata": {},
   "source": [
    "![animation](around-hill.gif \"Around hill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ec3b9f",
   "metadata": {},
   "source": [
    "### Going around hill (with local minimum)\n",
    "This one was unexpected. When playing with previous example I've suddenly discovered case which demonstrates Adam's ability to overcome local minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb3da9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    return tf.sin(3+ 1/(tf.square(x) + 0.45)) + tf.sin(3 + 1/(tf.square(y) + 0.45)) - 0.5*y\n",
    "\n",
    "x, y, z = evaluate_on_grid(0.5, f)\n",
    "#show_surface(x, y, z)\n",
    "\n",
    "start_x = np.float64(0.01)\n",
    "start_y = np.min(y) * 0.9\n",
    "\n",
    "filename = 'around-hill2.gif'\n",
    "\n",
    "gradient_steps = 100\n",
    "\n",
    "vertical_adjustment = (np.max(z) - np.min(z))/30\n",
    "optimizer_lines = [lines_optimizer(opt[2], f, start_x, start_y, (ind+1)*vertical_adjustment, number_of_steps=gradient_steps) for ind, opt in enumerate(optimizers)]\n",
    "\n",
    "create_animation(x, y, z, optimizer_lines, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c4e360",
   "metadata": {},
   "source": [
    "![animation](around-hill2.gif \"Around hill 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df941c4",
   "metadata": {},
   "source": [
    "### Sloped trenches\n",
    "Trenches have slope in the Y direction and have local minima. There is also a tiny slope in the X direction. Another example when Adam overcomes local minima. Both RMSprop and Adam respond to tiny slope as before. SGDs are paralyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f05fcc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    return  tf.square(tf.sin(20*y+3)/10+0.1)- 0.3*y - 0.0001*x\n",
    "\n",
    "x, y, z = evaluate_on_grid(0.5, f)\n",
    "#show_surface(x, y, z)\n",
    "\n",
    "start_x = np.min(x) * 0.9\n",
    "start_y = np.min(y) * 0.8\n",
    "\n",
    "filename = 'sloped-trenches.gif'\n",
    "\n",
    "gradient_steps = 100\n",
    "\n",
    "vertical_adjustment = (np.max(z) - np.min(z))/30\n",
    "optimizer_lines = [lines_optimizer(opt[2], f, start_x, start_y, (ind+1)*vertical_adjustment, number_of_steps=gradient_steps) for ind, opt in enumerate(optimizers)]\n",
    "\n",
    "create_animation(x, y, z, optimizer_lines, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be15792",
   "metadata": {},
   "source": [
    "![animation](sloped-trenches.gif \"Sloped trenches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc330538",
   "metadata": {},
   "source": [
    "### Circular pit\n",
    "Another surface causing troubles for SGDs and being overcomed by Adam easily. Note oscillation of Adam due to its momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e89da9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    return  tf.sin(tf.sqrt(tf.square(15*x) + tf.square(15*y)))/10 - 0.1*y\n",
    "\n",
    "x, y, z = evaluate_on_grid(0.5, f)\n",
    "#show_surface(x, y, z)\n",
    "\n",
    "start_x = np.float64(0.01)\n",
    "start_y = np.min(y) * 0.9\n",
    "\n",
    "filename = 'circular-pit.gif'\n",
    "\n",
    "gradient_steps = 100\n",
    "\n",
    "vertical_adjustment = (np.max(z) - np.min(z))/30\n",
    "optimizer_lines = [lines_optimizer(opt[2], f, start_x, start_y, (ind+1)*vertical_adjustment, number_of_steps=gradient_steps) for ind, opt in enumerate(optimizers)]\n",
    "\n",
    "create_animation(x, y, z, optimizer_lines, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13424519",
   "metadata": {},
   "source": [
    "![animation](circular-pit.gif \"Circular pit\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
